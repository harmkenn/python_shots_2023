{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygeodesy as pg \n",
    "\n",
    "# https://mrjean1.github.io/PyGeodesy/\n",
    "# https://www.movable-type.co.uk/scripts/latlong.html\n",
    "\n",
    "lat1d = 40\n",
    "lon1d = -122\n",
    "lat2d = 50 \n",
    "lon2d = 30\n",
    "\n",
    "lbd = pg.bearing(lat1d,lon1d,lat2d,lon2d) #Launch Bearing in degrees\n",
    "ibd = pg.bearing(lat2d,lon2d,lat1d,lon1d)-180 #impact Bearing in degrees\n",
    "if ibd < 0: ibd = ibd + 360\n",
    "\n",
    "# six different distances\n",
    "d1 = pg.cosineAndoyerLambert(lat1d,lon1d,lat2d,lon2d)\n",
    "d2 = pg.cosineForsytheAndoyerLambert(lat1d,lon1d,lat2d,lon2d) # This is the best one\n",
    "d3 = pg.cosineLaw(lat1d,lon1d,lat2d,lon2d)\n",
    "d4 = pg.haversine(lat1d,lon1d,lat2d,lon2d)\n",
    "d5 = pg.thomas(lat1d,lon1d,lat2d,lon2d)\n",
    "d6 = pg.thomas(lat1d,lon1d,lat2d,lon2d)\n",
    "\n",
    "# Compute the midpoint on the gun target line\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Assuming you have a pandas DataFrame called 'data' with columns X1, X2, X3, X4, Y1, Y2, Y3, Y4\n",
    "\n",
    "# Splitting the data into input features and output variables\n",
    "inputs = data[['X1', 'X2', 'X3', 'X4']]\n",
    "outputs = data[['Y1', 'Y2', 'Y3', 'Y4']]\n",
    "\n",
    "# Creating polynomial features\n",
    "degree = 2  # Set the degree of the polynomial\n",
    "poly_features = PolynomialFeatures(degree=degree)\n",
    "inputs_poly = poly_features.fit_transform(inputs)\n",
    "\n",
    "# Creating and training the polynomial regression model\n",
    "model = make_pipeline(poly_features, LinearRegression())\n",
    "model.fit(inputs_poly, outputs)\n",
    "\n",
    "# Now you can use the trained model to make predictions\n",
    "# Assuming you have a new DataFrame called 'new_data' with columns X1, X2, X3, X4\n",
    "new_inputs_poly = poly_features.transform(new_data)\n",
    "predictions = model.predict(new_inputs_poly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daddy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:413: UserWarning: X has feature names, but PolynomialFeatures was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 4 features, but PolynomialFeatures is expecting 15 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 39\u001b[0m\n\u001b[0;32m     33\u001b[0m new_data \u001b[39m=\u001b[39m [\n\u001b[0;32m     34\u001b[0m     [\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m6\u001b[39m, \u001b[39m7\u001b[39m],\n\u001b[0;32m     35\u001b[0m     [\u001b[39m5\u001b[39m, \u001b[39m6\u001b[39m, \u001b[39m7\u001b[39m, \u001b[39m8\u001b[39m]\n\u001b[0;32m     36\u001b[0m ]\n\u001b[0;32m     37\u001b[0m new_data_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(new_data, columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39mX1\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mX2\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mX3\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mX4\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m---> 39\u001b[0m new_inputs_poly \u001b[39m=\u001b[39m poly_features\u001b[39m.\u001b[39;49mtransform(new_data_df)\n\u001b[0;32m     40\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(new_inputs_poly)\n\u001b[0;32m     42\u001b[0m \u001b[39mprint\u001b[39m(predictions)\n",
      "File \u001b[1;32mc:\\Users\\Daddy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:142\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[0;32m    141\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 142\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    143\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    144\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    145\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    146\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[0;32m    147\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[0;32m    148\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Daddy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\preprocessing\\_polynomial.py:341\u001b[0m, in \u001b[0;36mPolynomialFeatures.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    311\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Transform data to polynomial features.\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \n\u001b[0;32m    313\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[39m    `csr_matrix`.\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    339\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 341\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m    342\u001b[0m     X, order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mF\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, accept_sparse\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    343\u001b[0m )\n\u001b[0;32m    345\u001b[0m n_samples, n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape\n\u001b[0;32m    347\u001b[0m \u001b[39mif\u001b[39;00m sparse\u001b[39m.\u001b[39misspmatrix_csr(X):\n",
      "File \u001b[1;32mc:\\Users\\Daddy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:569\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    566\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    568\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 569\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    571\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\Daddy\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:370\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    369\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 370\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    371\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    373\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 4 features, but PolynomialFeatures is expecting 15 features as input."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Assuming you have a list of data points with four inputs and four outputs\n",
    "data = [\n",
    "    [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "    [2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    [3, 4, 5, 6, 7, 8, 9, 10]\n",
    "]\n",
    "\n",
    "# Creating the pandas DataFrame with an index\n",
    "data_columns = ['X1', 'X2', 'X3', 'X4', 'Y1', 'Y2', 'Y3', 'Y4']\n",
    "data_index = ['data_point1', 'data_point2', 'data_point3']\n",
    "data_df = pd.DataFrame(data, columns=data_columns, index=data_index)\n",
    "\n",
    "# Splitting the data into input features and output variables\n",
    "inputs = data_df[['X1', 'X2', 'X3', 'X4']]\n",
    "outputs = data_df[['Y1', 'Y2', 'Y3', 'Y4']]\n",
    "\n",
    "# Creating polynomial features\n",
    "degree = 2  # Set the degree of the polynomial\n",
    "poly_features = PolynomialFeatures(degree=degree)\n",
    "inputs_poly = poly_features.fit_transform(inputs)\n",
    "\n",
    "# Creating and training the polynomial regression model\n",
    "model = make_pipeline(poly_features, LinearRegression())\n",
    "model.fit(inputs_poly, outputs)\n",
    "\n",
    "# Now you can use the trained model to make predictions\n",
    "# Assuming you have a new DataFrame called 'new_data' with columns X1, X2, X3, X4\n",
    "new_data = [\n",
    "    [4, 5, 6, 7],\n",
    "    [5, 6, 7, 8]\n",
    "]\n",
    "new_data_df = pd.DataFrame(new_data, columns=['X1', 'X2', 'X3', 'X4'])\n",
    "\n",
    "new_inputs_poly = poly_features.transform(new_data_df)\n",
    "predictions = model.predict(new_inputs_poly)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11.25        2.4375      2.34765625  8.625     ]\n",
      " [ 0.625       2.          1.50976562  0.125     ]\n",
      " [-1.          4.59375     3.45703125 -2.125     ]\n",
      " [ 8.375       2.03125     3.29296875  7.5       ]\n",
      " [ 3.375       2.09375    -1.2421875  11.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Generating random data\n",
    "np.random.seed(42)\n",
    "num_samples = 100\n",
    "inputs = pd.DataFrame(np.random.rand(num_samples, 4), columns=['X1', 'X2', 'X3', 'X4'])\n",
    "outputs = pd.DataFrame({\n",
    "    'Y1': 3 * inputs['X1'] ** 3 - 2 * inputs['X2'] ** 2 + 5 * inputs['X3'] + np.random.randn(num_samples),\n",
    "    'Y2': 2 * inputs['X1'] ** 2 + inputs['X2'] ** 3 + 4 * inputs['X4'] + np.random.randn(num_samples),\n",
    "    'Y3': 4 * inputs['X1'] + inputs['X2'] ** 2 - 3 * inputs['X3'] ** 3 + np.random.randn(num_samples),\n",
    "    'Y4': inputs['X1'] ** 2 + inputs['X2'] + 2 * inputs['X4'] ** 3 + np.random.randn(num_samples)\n",
    "})\n",
    "\n",
    "# Concatenating input features and output variables\n",
    "data = pd.concat([inputs, outputs], axis=1)\n",
    "\n",
    "# Splitting the data into input features and output variables\n",
    "input_features = data[['X1', 'X2', 'X3', 'X4']]\n",
    "output_variables = data[['Y1', 'Y2', 'Y3', 'Y4']]\n",
    "\n",
    "# Creating polynomial features\n",
    "degree = 3  # Set the degree of the polynomial\n",
    "poly_features = PolynomialFeatures(degree=degree)\n",
    "input_features_poly = poly_features.fit_transform(input_features)\n",
    "\n",
    "# Creating and training the polynomial regression model\n",
    "model = LinearRegression()\n",
    "model.fit(input_features_poly, output_variables)\n",
    "\n",
    "# Now you can use the trained model to make predictions\n",
    "# Assuming you have a new DataFrame called 'new_data' with columns X1, X2, X3, X4\n",
    "new_data = pd.DataFrame(np.random.rand(5, 4), columns=['X1', 'X2', 'X3', 'X4'])\n",
    "new_input_features_poly = poly_features.transform(new_data)\n",
    "predictions = model.predict(new_input_features_poly)\n",
    "\n",
    "print(predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f627b94a91bc915482d65575b2ea77ee7c3710ea9aacf075a668e3021bd93680"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
